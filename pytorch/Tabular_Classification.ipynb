{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f2fce1",
   "metadata": {},
   "source": [
    "Tabular Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90964846",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets --quiet\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/mssmartypants/rice-type-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef7e1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"/content/rice-type-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9f646",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Data reading and preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9b1c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"/content/rice-type-classification/riceClassification.csv\")\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3b4c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)\n",
    "data_df.drop([\"id\"], axis=1, inplace= True)  # Drop Id column # axis=0 row-wise operation # axis=1 column-wise operation       \n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae85ea3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\tArea\tMajorAxisLength\tMinorAxisLength\tEccentricity\tConvexArea\tEquivDiameter\tExtent\tPerimeter\tRoundness\tAspectRation\tClass\n",
    "0\t4537\t92.229316\t64.012769\t0.719916\t4677\t76.004525\t0.657536\t273.085\t0.764510\t1.440796\t1\n",
    "1\t2872\t74.691881\t51.400454\t0.725553\t3015\t60.471018\t0.713009\t208.317\t0.831658\t1.453137\t1\n",
    "2\t3048\t76.293164\t52.043491\t0.731211\t3132\t62.296341\t0.759153\t210.012\t0.868434\t1.465950\t1\n",
    "3\t3073\t77.033628\t51.928487\t0.738639\t3157\t62.551300\t0.783529\t210.657\t0.870203\t1.483456\t1\n",
    "4\t3693\t85.124785\t56.374021\t0.749282\t3802\t68.571668\t0.769375\t230.332\t0.874743\t1.510000\t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cd288",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae25a15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "original_df = data_df.copy() # Creating a copy of the original Dataframe to use to normalize inference\n",
    "\n",
    "for column in data_df.columns:\n",
    "  data_df[column] = data_df[column]/data_df[column].abs().max()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbc7f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Area\tMajorAxisLength\tMinorAxisLength\tEccentricity\tConvexArea\tEquivDiameter\tExtent\tPerimeter\tRoundness\tAspectRation\tClass\n",
    "0\t0.444368\t0.503404\t0.775435\t0.744658\t0.424873\t0.666610\t0.741661\t0.537029\t0.844997\t0.368316\t1.0\n",
    "1\t0.281293\t0.407681\t0.622653\t0.750489\t0.273892\t0.530370\t0.804230\t0.409661\t0.919215\t0.371471\t1.0\n",
    "2\t0.298531\t0.416421\t0.630442\t0.756341\t0.284520\t0.546380\t0.856278\t0.412994\t0.959862\t0.374747\t1.0\n",
    "3\t0.300979\t0.420463\t0.629049\t0.764024\t0.286791\t0.548616\t0.883772\t0.414262\t0.961818\t0.379222\t1.0\n",
    "4\t0.361704\t0.464626\t0.682901\t0.775033\t0.345385\t0.601418\t0.867808\t0.452954\t0.966836\t0.386007\t1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a64a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524e448",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256692d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np# Mathematical operations\n",
    "from sklearn.model_selection import train_test_split # Split the dataset (train, validation, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91924e18",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(data_df.iloc[:,:-1])# Get the inputs, all rows and all columns except last column (output)\n",
    "Y = np.array(data_df.iloc[:, -1])# Get the ouputs, all rows and last column only (output column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31a3e6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training set is: \", X_train.shape[0])\n",
    "print(\"Training set is: \", X_test.shape[0])\n",
    "print(\"Training set is: \", X_val.shape[0])\n",
    "\n",
    "\n",
    "Training set is:  12729\n",
    "Training set is:  2728\n",
    "Training set is:  2728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6ea58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf873a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mport torch # Torch main framework\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchsummary import summary # Visualize the model layers and number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cadd15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a409c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self,X, Y):\n",
    "    self.X = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    self.Y = torch.tensor(Y, dtype = torch.float32).to(device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.Y[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e59d5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "training_data = CustomDataset(X_train, Y_train)\n",
    "test_data = CustomDataset(X_test, Y_test)\n",
    "validate_data = CustomDataset(X_val,Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae25017",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8211e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "validate_data = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46852f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_LAYERS = 10\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "\n",
    "\n",
    "    self.input_layer = nn.Linear(X.shape[1], HIDDEN_LAYERS)\n",
    "    self.linear = nn.Linear(HIDDEN_LAYERS,1)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.input_layer(x)\n",
    "    x = self.linear(x)\n",
    "    x = self.sigmoid(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336ff6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel().to(device)\n",
    "summary(model, (X.shape[1],))\n",
    "\n",
    "----------------------------------------------------------------\n",
    "        Layer (type)               Output Shape         Param #\n",
    "================================================================\n",
    "            Linear-1                   [-1, 10]             110\n",
    "            Linear-2                    [-1, 1]              11\n",
    "           Sigmoid-3                    [-1, 1]               0\n",
    "================================================================\n",
    "Total params: 121\n",
    "Trainable params: 121\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.00\n",
    "Forward/backward pass size (MB): 0.00\n",
    "Params size (MB): 0.00\n",
    "Estimated Total Size (MB): 0.00\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4b925",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24420197",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam # Adam Optimizer\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce81bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Training\n",
    "Now we are ready exiciting part.we are training our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c262c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # -------- TRAINING ----------\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(inputs).squeeze(1)\n",
    "        loss = criterion(pred, labels)\n",
    "\n",
    "        # Backward pass and weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        total_acc += ((pred.round() == labels).sum().item()) / len(labels)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    avg_train_acc = total_acc / len(train_dataloader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accs.append(avg_train_acc)\n",
    "\n",
    "    # -------- VALIDATION ----------\n",
    "    total_val_loss = 0\n",
    "    total_val_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validate_data:\n",
    "            pred = model(inputs).squeeze(1)\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            total_val_acc += ((pred.round() == labels).sum().item()) / len(labels)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(validate_data)\n",
    "    avg_val_acc = total_val_acc / len(validate_data)\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accs.append(avg_val_acc)\n",
    "\n",
    "    # Print metrics per epoch\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce21084",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Epoch 1/10 | Train Loss: 0.0385, Train Acc: 0.9873 | Val Loss: 0.0449, Val Acc: 0.9834\n",
    "Epoch 2/10 | Train Loss: 0.0382, Train Acc: 0.9874 | Val Loss: 0.0431, Val Acc: 0.9855\n",
    "Epoch 3/10 | Train Loss: 0.0383, Train Acc: 0.9865 | Val Loss: 0.0436, Val Acc: 0.9836\n",
    "Epoch 4/10 | Train Loss: 0.0384, Train Acc: 0.9875 | Val Loss: 0.0434, Val Acc: 0.9836\n",
    "Epoch 5/10 | Train Loss: 0.0384, Train Acc: 0.9877 | Val Loss: 0.0436, Val Acc: 0.9856\n",
    "Epoch 6/10 | Train Loss: 0.0384, Train Acc: 0.9868 | Val Loss: 0.0432, Val Acc: 0.9851\n",
    "Epoch 7/10 | Train Loss: 0.0385, Train Acc: 0.9867 | Val Loss: 0.0460, Val Acc: 0.9838\n",
    "Epoch 8/10 | Train Loss: 0.0385, Train Acc: 0.9872 | Val Loss: 0.0433, Val Acc: 0.9852\n",
    "Epoch 9/10 | Train Loss: 0.0383, Train Acc: 0.9874 | Val Loss: 0.0447, Val Acc: 0.9836\n",
    "Epoch 10/10 | Train Loss: 0.0386, Train Acc: 0.9870 | Val Loss: 0.0437, Val Acc: 0.9847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab0c77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Testing\n",
    "Now in this section, we will be testing our model, we will start the code by with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77358937",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  total_loss_test = 0\n",
    "  total_acc_test = 0\n",
    "  for inputs, labels in test_dataloader:\n",
    "    prediction = model(inputs).squeeze(1)\n",
    "    loss = criterion(prediction, labels)\n",
    "\n",
    "    total_loss_test +=loss.item()\n",
    "    total_acc_test += ((prediction.round() == labels).sum().item())\n",
    "\n",
    "print(f\"Accuracy Score is: {round((total_acc_test/X_test.shape[0])*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de5e2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Accuracy Score is: 98.5%"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
